{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Entrainement du modèle de reconnaissance de symboles mathématiques","metadata":{}},{"cell_type":"code","source":"# La classe Image permet de charger et d'afficher des images dans un notebook Jupyter\nfrom IPython.display import Image","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.status.busy":"2023-03-21T19:23:17.298016Z","iopub.execute_input":"2023-03-21T19:23:17.298461Z","iopub.status.idle":"2023-03-21T19:23:17.331167Z","shell.execute_reply.started":"2023-03-21T19:23:17.298416Z","shell.execute_reply":"2023-03-21T19:23:17.329972Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Permet d'afficher l'image\nImage(\"/kaggle/input/hasyv2/hasy-data/v2-00010.png\")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:23:17.333519Z","iopub.execute_input":"2023-03-21T19:23:17.334301Z","iopub.status.idle":"2023-03-21T19:23:17.355753Z","shell.execute_reply.started":"2023-03-21T19:23:17.334259Z","shell.execute_reply":"2023-03-21T19:23:17.354447Z"},"trusted":true},"execution_count":2,"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAIAAAD8GO2jAAAAxklEQVR4nNWUQQ7FIAhE0fT+V7YLEmMVYUBcdFa/zYcHA6W01khVKWV9aUZ1VfB/CFXUAybqJeOpWVoHa3b+zY8gybZIsRthBGeQMGSzOtAoowO9UqSPoEWj9CZkgHcX3QAWPskgIEWnAHOXjFPh1Uhi9imgZ9w1sQW4Ds4YMkmYgXdH9WUzLDrf1Jw1VerI/A5Eb2VAwJldyAw4vEJruNBBygmSAYlHVAZQdvkfwI3y6QfnGgVc8oemDtInPANuqNJNf4joBQaUSEpgitA1AAAAAElFTkSuQmCC\n","text/plain":"<IPython.core.display.Image object>"},"metadata":{}}]},{"cell_type":"code","source":"# csv : une bibliothèque pour la manipulation de fichiers CSV (Comma-Separated Values), souvent utilisée pour stocker des données tabulaires.\n# PIL : une bibliothèque pour la manipulation d'images en Python.\n# keras.preprocessing.image : une bibliothèque pour le prétraitement d'images avant l'apprentissage automatique.\nimport csv\nfrom PIL import Image as pil_image\nimport keras.preprocessing.image","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:23:17.356924Z","iopub.execute_input":"2023-03-21T19:23:17.357523Z","iopub.status.idle":"2023-03-21T19:23:27.366251Z","shell.execute_reply.started":"2023-03-21T19:23:17.357481Z","shell.execute_reply":"2023-03-21T19:23:27.364764Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# On lit le fichier csv et on ne garde que les 50 premières images de chaque caractère, car sinon ça sera trop long pour exécuter et ça utilisera trop de ram\n# On utilise keras.preprocessing.image.image_utils.img_to_array au lieu de keras.preprocessing.image.img_to_array, car on n'a pas la même version que sur le livre\n# On stock ensuite chaque image dans un tableau avec des valeurs entre 0 et 1 \nimgs = []\nclasses = {}\nwith open('/kaggle/input/hasyv2/hasy-data-labels.csv') as csvfile:\n    csvreader = csv.reader(csvfile)\n    i = 0\n    for row in csvreader:\n        if i > 0:\n            img_class = row[2]\n            if img_class not in classes:\n                classes[img_class] = 0\n            if classes[img_class] < 50:\n                img = keras.preprocessing.image.image_utils.img_to_array(pil_image.open(\"/kaggle/input/hasyv2/\" + row[0]))\n                img /= 255.0\n                imgs.append((row[0], img_class, img))\n                classes[img_class] += 1\n        i += 1\n\nclasses = list(classes.keys())","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:23:27.369046Z","iopub.execute_input":"2023-03-21T19:23:27.369812Z","iopub.status.idle":"2023-03-21T19:26:21.719199Z","shell.execute_reply.started":"2023-03-21T19:23:27.369771Z","shell.execute_reply":"2023-03-21T19:26:21.717814Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"imgs[0]","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:26:21.720810Z","iopub.execute_input":"2023-03-21T19:26:21.721163Z","iopub.status.idle":"2023-03-21T19:26:21.732046Z","shell.execute_reply.started":"2023-03-21T19:26:21.721130Z","shell.execute_reply":"2023-03-21T19:26:21.730867Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"('hasy-data/v2-00000.png',\n 'A',\n array([[[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.],\n         ...,\n         [1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]],\n \n        [[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.],\n         ...,\n         [1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]],\n \n        [[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.],\n         ...,\n         [1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]],\n \n        ...,\n \n        [[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.],\n         ...,\n         [1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]],\n \n        [[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.],\n         ...,\n         [1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]],\n \n        [[1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.],\n         ...,\n         [1., 1., 1.],\n         [1., 1., 1.],\n         [1., 1., 1.]]], dtype=float32))"},"metadata":{}}]},{"cell_type":"code","source":"len(imgs)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:26:21.733837Z","iopub.execute_input":"2023-03-21T19:26:21.734463Z","iopub.status.idle":"2023-03-21T19:26:21.745357Z","shell.execute_reply.started":"2023-03-21T19:26:21.734415Z","shell.execute_reply":"2023-03-21T19:26:21.744312Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"18450"},"metadata":{}}]},{"cell_type":"code","source":"import random\n\nrandom.shuffle(imgs)\nsplit_idx = int(0.8*len(imgs))\ntrain = imgs[:split_idx]\ntest = imgs[split_idx:]","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:26:21.746887Z","iopub.execute_input":"2023-03-21T19:26:21.747306Z","iopub.status.idle":"2023-03-21T19:26:21.777033Z","shell.execute_reply.started":"2023-03-21T19:26:21.747264Z","shell.execute_reply":"2023-03-21T19:26:21.775922Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ntrain_input = np.asarray(list(map(lambda row: row[2], train)))\ntest_input = np.asarray(list(map(lambda row: row[2], test)))\n\ntrain_output = np.asarray(list(map(lambda row: row[1], train)))\ntest_output = np.asarray(list(map(lambda row: row[1], test)))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:26:21.778347Z","iopub.execute_input":"2023-03-21T19:26:21.778700Z","iopub.status.idle":"2023-03-21T19:26:21.932940Z","shell.execute_reply.started":"2023-03-21T19:26:21.778668Z","shell.execute_reply":"2023-03-21T19:26:21.931703Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:26:21.934702Z","iopub.execute_input":"2023-03-21T19:26:21.935256Z","iopub.status.idle":"2023-03-21T19:26:22.222256Z","shell.execute_reply.started":"2023-03-21T19:26:21.935199Z","shell.execute_reply":"2023-03-21T19:26:22.220883Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# convert class names into one-hot encoding\n\n# first, convert class names into integers\nlabel_encoder = LabelEncoder()\ninteger_encoded = label_encoder.fit_transform(classes)\n\n# then convert integers into one-hot encoding\nonehot_encoder = OneHotEncoder(sparse=False)\ninteger_encoded = integer_encoded.reshape(len(integer_encoded), 1)\nonehot_encoder.fit(integer_encoded)\n\n# convert train and test output to one-hot\ntrain_output_int = label_encoder.transform(train_output)\ntrain_output = onehot_encoder.transform(train_output_int.reshape(len(train_output_int), 1))\ntest_output_int = label_encoder.transform(test_output)\ntest_output = onehot_encoder.transform(test_output_int.reshape(len(test_output_int), 1))\n\nnum_classes = len(label_encoder.classes_)\nprint(\"Number of classes: %d\" % num_classes)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:26:22.225804Z","iopub.execute_input":"2023-03-21T19:26:22.226125Z","iopub.status.idle":"2023-03-21T19:26:22.344725Z","shell.execute_reply.started":"2023-03-21T19:26:22.226093Z","shell.execute_reply":"2023-03-21T19:26:22.343514Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Number of classes: 369\n","output_type":"stream"}]},{"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:26:22.348404Z","iopub.execute_input":"2023-03-21T19:26:22.348766Z","iopub.status.idle":"2023-03-21T19:26:22.353727Z","shell.execute_reply.started":"2023-03-21T19:26:22.348730Z","shell.execute_reply":"2023-03-21T19:26:22.352810Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\", input_shape=np.shape(train_input[0])))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(32, (3, 3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation=\"tanh\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation=\"softmax\"))\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:26:22.355219Z","iopub.execute_input":"2023-03-21T19:26:22.355596Z","iopub.status.idle":"2023-03-21T19:26:22.654041Z","shell.execute_reply.started":"2023-03-21T19:26:22.355560Z","shell.execute_reply":"2023-03-21T19:26:22.652892Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"Model: \"sequential\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d (Conv2D)             (None, 30, 30, 32)        896       \n                                                                 \n max_pooling2d (MaxPooling2D  (None, 15, 15, 32)       0         \n )                                                               \n                                                                 \n conv2d_1 (Conv2D)           (None, 13, 13, 32)        9248      \n                                                                 \n max_pooling2d_1 (MaxPooling  (None, 6, 6, 32)         0         \n 2D)                                                             \n                                                                 \n flatten (Flatten)           (None, 1152)              0         \n                                                                 \n dense (Dense)               (None, 1024)              1180672   \n                                                                 \n dropout (Dropout)           (None, 1024)              0         \n                                                                 \n dense_1 (Dense)             (None, 369)               378225    \n                                                                 \n=================================================================\nTotal params: 1,569,041\nTrainable params: 1,569,041\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"import keras.callbacks\n\ntensorboard = keras.callbacks.TensorBoard(log_dir=\"./logs/mnist-style\")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:26:22.655369Z","iopub.execute_input":"2023-03-21T19:26:22.655726Z","iopub.status.idle":"2023-03-21T19:26:22.663352Z","shell.execute_reply.started":"2023-03-21T19:26:22.655693Z","shell.execute_reply":"2023-03-21T19:26:22.661899Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"model.fit(train_input, train_output, batch_size=32, epochs=10, verbose=2, validation_split=0.2, callbacks=[tensorboard])","metadata":{"execution":{"iopub.status.busy":"2023-03-21T19:26:22.665692Z","iopub.execute_input":"2023-03-21T19:26:22.666016Z","iopub.status.idle":"2023-03-21T19:28:16.939184Z","shell.execute_reply.started":"2023-03-21T19:26:22.665985Z","shell.execute_reply":"2023-03-21T19:28:16.938110Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Epoch 1/10\n369/369 - 13s - loss: 4.1768 - accuracy: 0.1854 - val_loss: 2.3881 - val_accuracy: 0.4329 - 13s/epoch - 35ms/step\nEpoch 2/10\n369/369 - 12s - loss: 2.0572 - accuracy: 0.4912 - val_loss: 1.8811 - val_accuracy: 0.5288 - 12s/epoch - 31ms/step\nEpoch 3/10\n369/369 - 11s - loss: 1.5129 - accuracy: 0.5928 - val_loss: 1.7340 - val_accuracy: 0.5552 - 11s/epoch - 31ms/step\nEpoch 4/10\n369/369 - 11s - loss: 1.2093 - accuracy: 0.6568 - val_loss: 1.6562 - val_accuracy: 0.5833 - 11s/epoch - 30ms/step\nEpoch 5/10\n369/369 - 11s - loss: 1.0009 - accuracy: 0.7116 - val_loss: 1.6988 - val_accuracy: 0.5728 - 11s/epoch - 30ms/step\nEpoch 6/10\n369/369 - 11s - loss: 0.8442 - accuracy: 0.7496 - val_loss: 1.7616 - val_accuracy: 0.5728 - 11s/epoch - 31ms/step\nEpoch 7/10\n369/369 - 11s - loss: 0.7370 - accuracy: 0.7743 - val_loss: 1.8335 - val_accuracy: 0.5732 - 11s/epoch - 30ms/step\nEpoch 8/10\n369/369 - 11s - loss: 0.6134 - accuracy: 0.8056 - val_loss: 1.8843 - val_accuracy: 0.5745 - 11s/epoch - 30ms/step\nEpoch 9/10\n369/369 - 11s - loss: 0.5476 - accuracy: 0.8278 - val_loss: 1.9477 - val_accuracy: 0.5793 - 11s/epoch - 31ms/step\nEpoch 10/10\n369/369 - 11s - loss: 0.5159 - accuracy: 0.8399 - val_loss: 2.0101 - val_accuracy: 0.5779 - 11s/epoch - 30ms/step\n","output_type":"stream"},{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7f82b00f0790>"},"metadata":{}}]},{"cell_type":"code","source":"import time\n\nresults = []\n\nfor conv2d_count in [1,2]:\n    for dense_size in [128,256,512]:\n        for dropout in [0.0, 0.25, 0.50, 0.75]:\n            model = Sequential()\n            \n            for i in range(conv2d_count):\n                if i == 0:\n                    model.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\", input_shape=np.shape(train_input[0])))\n                else:\n                    model.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\"))\n                model.add(MaxPooling2D(pool_size=(2,2)))\n            model.add(Flatten())\n            model.add(Dense(dense_size, activation=\"tanh\"))\n            \n            if dropout > 0.0:\n                model.add(Dropout(dropout))\n            model.add(Dense(num_classes, activation=\"softmax\"))\n            \n            model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n            \n            log_dir = \"./logs/conv2d_%d-dense_%d-dropout_%.2f\" % (conv2d_count, dense_size, dropout)\n            tensorboard = keras.callbacks.TensorBoard(log_dir=log_dir)\n            \n            start = time.time()\n            model.fit(train_input, train_output, batch_size=32, epochs=10, verbose=0, validation_split=0.2, callbacks=[tensorboard])\n            score = model.evaluate(test_input, test_output, verbose=2)\n            end = time.time()\n            \n            print(\"Conv2D count: %d, Dense size: %d, Dropout: %.2f - Loss: %.2f, Accuracy: %.2f, Time: %d sec\" % (conv2d_count, dense_size, dropout, score[0], score[1], end - start))","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2023-03-21T19:28:16.940721Z","iopub.execute_input":"2023-03-21T19:28:16.941429Z","iopub.status.idle":"2023-03-21T20:08:04.792680Z","shell.execute_reply.started":"2023-03-21T19:28:16.941353Z","shell.execute_reply":"2023-03-21T20:08:04.791883Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"116/116 - 1s - loss: 1.6770 - accuracy: 0.5778 - 709ms/epoch - 6ms/step\nConv2D count: 1, Dense size: 128, Dropout: 0.00 - Loss: 1.68, Accuracy: 0.58, Time: 68 sec\n116/116 - 1s - loss: 1.5497 - accuracy: 0.5938 - 662ms/epoch - 6ms/step\nConv2D count: 1, Dense size: 128, Dropout: 0.25 - Loss: 1.55, Accuracy: 0.59, Time: 68 sec\n116/116 - 1s - loss: 1.5557 - accuracy: 0.5873 - 667ms/epoch - 6ms/step\nConv2D count: 1, Dense size: 128, Dropout: 0.50 - Loss: 1.56, Accuracy: 0.59, Time: 83 sec\n116/116 - 1s - loss: 1.5968 - accuracy: 0.5976 - 673ms/epoch - 6ms/step\nConv2D count: 1, Dense size: 128, Dropout: 0.75 - Loss: 1.60, Accuracy: 0.60, Time: 83 sec\n116/116 - 1s - loss: 1.6406 - accuracy: 0.5911 - 814ms/epoch - 7ms/step\nConv2D count: 1, Dense size: 256, Dropout: 0.00 - Loss: 1.64, Accuracy: 0.59, Time: 91 sec\n116/116 - 1s - loss: 1.6142 - accuracy: 0.5913 - 816ms/epoch - 7ms/step\nConv2D count: 1, Dense size: 256, Dropout: 0.25 - Loss: 1.61, Accuracy: 0.59, Time: 94 sec\n116/116 - 1s - loss: 1.5689 - accuracy: 0.5883 - 812ms/epoch - 7ms/step\nConv2D count: 1, Dense size: 256, Dropout: 0.50 - Loss: 1.57, Accuracy: 0.59, Time: 143 sec\n116/116 - 1s - loss: 1.4212 - accuracy: 0.6136 - 782ms/epoch - 7ms/step\nConv2D count: 1, Dense size: 256, Dropout: 0.75 - Loss: 1.42, Accuracy: 0.61, Time: 94 sec\n116/116 - 1s - loss: 1.7079 - accuracy: 0.5970 - 1s/epoch - 9ms/step\nConv2D count: 1, Dense size: 512, Dropout: 0.00 - Loss: 1.71, Accuracy: 0.60, Time: 144 sec\n116/116 - 1s - loss: 1.7038 - accuracy: 0.6027 - 1s/epoch - 9ms/step\nConv2D count: 1, Dense size: 512, Dropout: 0.25 - Loss: 1.70, Accuracy: 0.60, Time: 143 sec\n116/116 - 1s - loss: 1.7546 - accuracy: 0.5889 - 1s/epoch - 9ms/step\nConv2D count: 1, Dense size: 512, Dropout: 0.50 - Loss: 1.75, Accuracy: 0.59, Time: 147 sec\n116/116 - 1s - loss: 1.6642 - accuracy: 0.5862 - 1s/epoch - 9ms/step\nConv2D count: 1, Dense size: 512, Dropout: 0.75 - Loss: 1.66, Accuracy: 0.59, Time: 143 sec\n116/116 - 1s - loss: 1.4584 - accuracy: 0.6051 - 736ms/epoch - 6ms/step\nConv2D count: 2, Dense size: 128, Dropout: 0.00 - Loss: 1.46, Accuracy: 0.61, Time: 83 sec\n116/116 - 1s - loss: 1.4177 - accuracy: 0.6057 - 733ms/epoch - 6ms/step\nConv2D count: 2, Dense size: 128, Dropout: 0.25 - Loss: 1.42, Accuracy: 0.61, Time: 77 sec\n116/116 - 1s - loss: 1.3834 - accuracy: 0.6125 - 749ms/epoch - 6ms/step\nConv2D count: 2, Dense size: 128, Dropout: 0.50 - Loss: 1.38, Accuracy: 0.61, Time: 79 sec\n116/116 - 1s - loss: 1.5656 - accuracy: 0.5897 - 732ms/epoch - 6ms/step\nConv2D count: 2, Dense size: 128, Dropout: 0.75 - Loss: 1.57, Accuracy: 0.59, Time: 78 sec\n116/116 - 1s - loss: 1.4630 - accuracy: 0.6111 - 757ms/epoch - 7ms/step\nConv2D count: 2, Dense size: 256, Dropout: 0.00 - Loss: 1.46, Accuracy: 0.61, Time: 83 sec\n116/116 - 1s - loss: 1.4039 - accuracy: 0.6293 - 814ms/epoch - 7ms/step\nConv2D count: 2, Dense size: 256, Dropout: 0.25 - Loss: 1.40, Accuracy: 0.63, Time: 83 sec\n116/116 - 1s - loss: 1.3829 - accuracy: 0.6225 - 791ms/epoch - 7ms/step\nConv2D count: 2, Dense size: 256, Dropout: 0.50 - Loss: 1.38, Accuracy: 0.62, Time: 83 sec\n116/116 - 1s - loss: 1.3709 - accuracy: 0.6154 - 804ms/epoch - 7ms/step\nConv2D count: 2, Dense size: 256, Dropout: 0.75 - Loss: 1.37, Accuracy: 0.62, Time: 82 sec\n116/116 - 1s - loss: 1.6421 - accuracy: 0.6033 - 835ms/epoch - 7ms/step\nConv2D count: 2, Dense size: 512, Dropout: 0.00 - Loss: 1.64, Accuracy: 0.60, Time: 143 sec\n116/116 - 1s - loss: 1.6324 - accuracy: 0.5997 - 870ms/epoch - 7ms/step\nConv2D count: 2, Dense size: 512, Dropout: 0.25 - Loss: 1.63, Accuracy: 0.60, Time: 93 sec\n116/116 - 1s - loss: 1.5219 - accuracy: 0.6119 - 832ms/epoch - 7ms/step\nConv2D count: 2, Dense size: 512, Dropout: 0.50 - Loss: 1.52, Accuracy: 0.61, Time: 92 sec\n116/116 - 1s - loss: 1.3810 - accuracy: 0.6290 - 832ms/epoch - 7ms/step\nConv2D count: 2, Dense size: 512, Dropout: 0.75 - Loss: 1.38, Accuracy: 0.63, Time: 95 sec\n","output_type":"stream"}]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Conv2D(32, kernel_size=(3,3), activation=\"relu\", input_shape=np.shape(train_input[0])))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Conv2D(32, (3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(128, activation=\"tanh\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes, activation=\"softmax\"))\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nprint(model.summary())\n\n# join train and test data so we train the network on all data we have available to us\nmodel.fit(np.concatenate((train_input, test_input)), np.concatenate((train_output, test_output)), batch_size=32, epochs=10, verbose=2)\n\n# save the trained model\nmodel.save(\"mathsymbols.model\")\n\n# save label encoder (to reverse one-hot encoding)\nnp.save(\"classes.npy\", label_encoder.classes_)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T20:08:04.794352Z","iopub.execute_input":"2023-03-21T20:08:04.794697Z","iopub.status.idle":"2023-03-21T20:09:55.293473Z","shell.execute_reply.started":"2023-03-21T20:08:04.794664Z","shell.execute_reply":"2023-03-21T20:09:55.292319Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Model: \"sequential_25\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_38 (Conv2D)          (None, 30, 30, 32)        896       \n                                                                 \n max_pooling2d_38 (MaxPoolin  (None, 15, 15, 32)       0         \n g2D)                                                            \n                                                                 \n conv2d_39 (Conv2D)          (None, 13, 13, 32)        9248      \n                                                                 \n max_pooling2d_39 (MaxPoolin  (None, 6, 6, 32)         0         \n g2D)                                                            \n                                                                 \n flatten_25 (Flatten)        (None, 1152)              0         \n                                                                 \n dense_50 (Dense)            (None, 128)               147584    \n                                                                 \n dropout_19 (Dropout)        (None, 128)               0         \n                                                                 \n dense_51 (Dense)            (None, 369)               47601     \n                                                                 \n=================================================================\nTotal params: 205,329\nTrainable params: 205,329\nNon-trainable params: 0\n_________________________________________________________________\nNone\nEpoch 1/10\n577/577 - 12s - loss: 4.6105 - accuracy: 0.1293 - 12s/epoch - 20ms/step\nEpoch 2/10\n577/577 - 11s - loss: 2.7624 - accuracy: 0.3712 - 11s/epoch - 19ms/step\nEpoch 3/10\n577/577 - 11s - loss: 2.1215 - accuracy: 0.4818 - 11s/epoch - 18ms/step\nEpoch 4/10\n577/577 - 11s - loss: 1.8154 - accuracy: 0.5358 - 11s/epoch - 18ms/step\nEpoch 5/10\n577/577 - 11s - loss: 1.6213 - accuracy: 0.5733 - 11s/epoch - 19ms/step\nEpoch 6/10\n577/577 - 11s - loss: 1.4765 - accuracy: 0.5973 - 11s/epoch - 18ms/step\nEpoch 7/10\n577/577 - 11s - loss: 1.3729 - accuracy: 0.6171 - 11s/epoch - 18ms/step\nEpoch 8/10\n577/577 - 11s - loss: 1.2951 - accuracy: 0.6341 - 11s/epoch - 19ms/step\nEpoch 9/10\n577/577 - 11s - loss: 1.2369 - accuracy: 0.6476 - 11s/epoch - 19ms/step\nEpoch 10/10\n577/577 - 11s - loss: 1.1765 - accuracy: 0.6586 - 11s/epoch - 19ms/step\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Utilisation du modèle de reconnaissance de symboles mathématiques","metadata":{}},{"cell_type":"code","source":"# Load the pre-trained model and predict the math symbol for an arbitrary image; the code below could be placed in a separate file\n\nimport keras.models\n\nmodel2 = keras.models.load_model(\"mathsymbols.model\")\nprint(model2.summary())\n\n# restore the class name to integer encoder\nlabel_encoder2 = LabelEncoder()\nlabel_encoder2.classes_ = np.load(\"classes.npy\")\n\ndef predict(img_path):\n    newimg = keras.preprocessing.image.image_utils.img_to_array(pil_image.open(img_path))\n    newimg /= 255.0\n    \n    # do the prediction\n    prediction = model2.predict(newimg.reshape(1, 32, 32, 3))\n    \n    # figure out whitch output neuron had the highest score, and reverse the one-hot encoding\n    inverted = label_encoder2.inverse_transform([np.argmax(prediction)]) # argmax finds highest-scoring output\n    print(\"Prediction: %s, confidence: %.2f\" % (inverted[0], np.max(prediction)))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T20:09:55.294898Z","iopub.execute_input":"2023-03-21T20:09:55.295215Z","iopub.status.idle":"2023-03-21T20:09:55.775952Z","shell.execute_reply.started":"2023-03-21T20:09:55.295184Z","shell.execute_reply":"2023-03-21T20:09:55.774824Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"Model: \"sequential_25\"\n_________________________________________________________________\n Layer (type)                Output Shape              Param #   \n=================================================================\n conv2d_38 (Conv2D)          (None, 30, 30, 32)        896       \n                                                                 \n max_pooling2d_38 (MaxPoolin  (None, 15, 15, 32)       0         \n g2D)                                                            \n                                                                 \n conv2d_39 (Conv2D)          (None, 13, 13, 32)        9248      \n                                                                 \n max_pooling2d_39 (MaxPoolin  (None, 6, 6, 32)         0         \n g2D)                                                            \n                                                                 \n flatten_25 (Flatten)        (None, 1152)              0         \n                                                                 \n dense_50 (Dense)            (None, 128)               147584    \n                                                                 \n dropout_19 (Dropout)        (None, 128)               0         \n                                                                 \n dense_51 (Dense)            (None, 369)               47601     \n                                                                 \n=================================================================\nTotal params: 205,329\nTrainable params: 205,329\nNon-trainable params: 0\n_________________________________________________________________\nNone\n","output_type":"stream"}]},{"cell_type":"code","source":"predict(\"/kaggle/input/hasyv2/hasy-data/v2-00010.png\")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T20:09:55.777843Z","iopub.execute_input":"2023-03-21T20:09:55.778143Z","iopub.status.idle":"2023-03-21T20:09:55.970569Z","shell.execute_reply.started":"2023-03-21T20:09:55.778113Z","shell.execute_reply":"2023-03-21T20:09:55.969373Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 115ms/step\nPrediction: A, confidence: 0.26\n","output_type":"stream"}]},{"cell_type":"code","source":"predict(\"/kaggle/input/hasyv2/hasy-data/v2-00500.png\")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T20:09:55.972252Z","iopub.execute_input":"2023-03-21T20:09:55.972600Z","iopub.status.idle":"2023-03-21T20:09:56.047482Z","shell.execute_reply.started":"2023-03-21T20:09:55.972566Z","shell.execute_reply":"2023-03-21T20:09:56.046378Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 22ms/step\nPrediction: \\pi, confidence: 0.36\n","output_type":"stream"}]},{"cell_type":"code","source":"predict(\"/kaggle/input/hasyv2/hasy-data/v2-00700.png\")","metadata":{"execution":{"iopub.status.busy":"2023-03-21T20:09:56.049244Z","iopub.execute_input":"2023-03-21T20:09:56.050068Z","iopub.status.idle":"2023-03-21T20:09:56.124482Z","shell.execute_reply.started":"2023-03-21T20:09:56.050020Z","shell.execute_reply":"2023-03-21T20:09:56.123328Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"1/1 [==============================] - 0s 22ms/step\nPrediction: \\alpha, confidence: 0.48\n","output_type":"stream"}]}]}